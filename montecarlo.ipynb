{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localization\n",
    "\n",
    "![](https://docs.google.com/drawings/d/e/2PACX-1vQ2SQeGNXvVybIzZW9Bp2cBFE2wQyrzh7vf6MCxzS-JAQvw-97nyyafxblGoWOAL5T8j9LwqcDWgXFV/pub?w=1121&h=204)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evironment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "x_noise = 3\n",
    "kernel_size = 6\n",
    "kernel = norm.pdf(np.arange(-kernel_size, kernel_size+1), scale=x_noise)\n",
    "kernel /= np.sum(kernel)\n",
    "n = 200\n",
    "X = range(n)\n",
    "z_noise = 0.006\n",
    "width = 1560\n",
    "env_map = np.array([280.5, 480.5, 1280.5])\n",
    "sensor_spread = 25\n",
    "\n",
    "robot_img = mpimg.imread('robot.png')\n",
    "doors_img = mpimg.imread('doors.png')\n",
    "\n",
    "(h, w, _) = robot_img.shape\n",
    "\n",
    "def get_measurement(true_state):\n",
    "    v = np.min(abs(env_map - true_state))\n",
    "    return norm.pdf(v, scale=sensor_spread) + np.random.normal(scale=z_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Step\n",
    "Here you will implement a function that takes the prior and incorporates a control signal. The control signal will be either move one space to the left or one space to the right. Important: the robot executes the control signal succesfully 90% of the time and remains in the same place 10% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prior, env_map, u):\n",
    "    i = int(u*n/width + 0.5)\n",
    "    posterior = np.roll(prior, i)\n",
    "    if i > 0:\n",
    "        posterior[0:i] = 0\n",
    "    else:\n",
    "        posterior[i:] = 0\n",
    "    return np.convolve(posterior, kernel, mode='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correction Step\n",
    "\n",
    "Here you will implement a function that takes the prior (probability distribution at the previous timestep) and incorporates a color sensor reading. **Important**: The color sensor gives a correct reading 80% of the time and an incorrect reading 20% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement_probability(env_map, z):\n",
    "    # create empty array\n",
    "    prob = np.zeros(n)\n",
    "    \n",
    "    # for each bin in the histogram\n",
    "    for i in range(prob.size):\n",
    "        # compute the position this bin represents\n",
    "        x = float(i)/n * width + 0.5\n",
    "        # compute the expected measurement at this location\n",
    "        expected = norm.pdf(np.min(abs(env_map - x)), scale=sensor_spread)\n",
    "        # compute the measurement probability\n",
    "        prob[i] = norm.pdf(expected - z, scale=z_noise)\n",
    "\n",
    "    return prob\n",
    "\n",
    "def correct(prior, prob):\n",
    "    posterior = np.multiply(prior, prob)\n",
    "    # normalize so probabilities sum to 1\n",
    "    posterior = posterior / np.sum(posterior)\n",
    "    \n",
    "    return posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you complete this, scroll down to results and run the initial belief and sense RED codeblocks. Check to make sure the distribution moves as you'd expect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you complete the move function, run all the codeblocks to see how your distribution changes. Does it shift as expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "belief = np.array([1./n]*n)\n",
    "true_state = 180.5\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize = (15,5))\n",
    "x = int(true_state - w/2 + 0.5)\n",
    "world = np.copy(doors_img)\n",
    "world[70:70+h,x:x+w][robot_img[:,:,3]==1] = robot_img[robot_img[:,:,3]==1]\n",
    "ax1.imshow(world)\n",
    "ax2.set_ylim([0, 0.25]); ax2.set_xlim([0, n]); ax2.bar(X, belief)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 100\n",
    "true_state += u\n",
    "belief = predict(belief, env_map, u + np.random.normal(scale=x_noise))\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize = (15,5))\n",
    "x = int(true_state - w/2 + 0.5)\n",
    "world = np.copy(doors_img)\n",
    "world[70:70+h,x:x+w][robot_img[:,:,3]==1] = robot_img[robot_img[:,:,3]==1]\n",
    "ax1.imshow(world)\n",
    "ax2.set_ylim([0, 0.25]); ax2.set_xlim([0, n]); ax2.bar(X, belief)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sense for doors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z = 0.015013100198017304 #get_measurement(true_state)\n",
    "prob = measurement_probability(env_map, z)\n",
    "belief = correct(belief, prob)\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize = (15,7))\n",
    "x = int(true_state - w/2 + 0.5)\n",
    "world = np.copy(doors_img)\n",
    "world[70:70+h,x:x+w][robot_img[:,:,3]==1] = robot_img[robot_img[:,:,3]==1]\n",
    "ax1.imshow(world)\n",
    "ax2.set_xlim([0, n]); ax2.bar(X, prob)\n",
    "ax3.set_ylim([0, 0.25]); ax3.set_xlim([0, n]); ax3.bar(X, belief)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 200\n",
    "true_state += u\n",
    "belief = predict(belief, env_map, u + np.random.normal(scale=x_noise))\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize = (15,5))\n",
    "x = int(true_state - w/2 + 0.5)\n",
    "world = np.copy(doors_img)\n",
    "world[70:70+h,x:x+w][robot_img[:,:,3]==1] = robot_img[robot_img[:,:,3]==1]\n",
    "ax1.imshow(world)\n",
    "ax2.set_ylim([0, 0.25]); ax2.set_xlim([0, n]); ax2.bar(X, belief)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sense for doors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0.018461221294540399 #get_measurement(true_state)\n",
    "prob = measurement_probability(env_map, z)\n",
    "belief = correct(belief, prob)\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize = (15,7))\n",
    "x = int(true_state - w/2 + 0.5)\n",
    "world = np.copy(doors_img)\n",
    "world[70:70+h,x:x+w][robot_img[:,:,3]==1] = robot_img[robot_img[:,:,3]==1]\n",
    "ax1.imshow(world)\n",
    "ax2.set_xlim([0, n]); ax2.bar(X, prob)\n",
    "ax3.set_ylim([0, 0.25]); ax3.set_xlim([0, n]); ax3.bar(X, belief)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 300\n",
    "true_state += u\n",
    "belief = predict(belief, env_map, u + np.random.normal(scale=x_noise))\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize = (15,5))\n",
    "x = int(true_state - w/2 + 0.5)\n",
    "world = np.copy(doors_img)\n",
    "world[70:70+h,x:x+w][robot_img[:,:,3]==1] = robot_img[robot_img[:,:,3]==1]\n",
    "ax1.imshow(world)\n",
    "ax2.set_ylim([0, 0.25]); ax2.set_xlim([0, n]); ax2.bar(X, belief)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sense for doors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0.0044673532993354101 # get_measurement(true_state)\n",
    "prob = measurement_probability(env_map, z)\n",
    "belief = correct(belief, prob)\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize = (15,7))\n",
    "x = int(true_state - w/2 + 0.5)\n",
    "world = np.copy(doors_img)\n",
    "world[70:70+h,x:x+w][robot_img[:,:,3]==1] = robot_img[robot_img[:,:,3]==1]\n",
    "ax1.imshow(world)\n",
    "ax2.set_xlim([0, n]); ax2.bar(X, prob)\n",
    "ax3.set_ylim([0, 0.25]); ax3.set_xlim([0, n]); ax3.bar(X, belief)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
